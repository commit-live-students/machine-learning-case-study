### Pre-Reads

Read [Generalized Linear Models (GLM)](http://www.wright.edu/~thaddeus.tarpey/ES714glm.pdf), focusing on section one, _Logistic Regression_.
 * Check out this [deck](http://www.mc.vanderbilt.edu/gcrc/workshop_files/2004-11-12.pdf) introducing logistic regression.
 * Read [William King's logistic regression tutorial](http://ww2.coastal.edu/kingw/statistics/R-tutorials/logistic.html) with examples in `R`. It explains terms nicely and gives good illustrative examples.

### Session Slides

@[gslides](1WjKrm7e0CP5ItcyvnnTedH4zfmqZNYqzJaF0aqCqeyk)

### Post Reads

Optional:

 * Read [Generative and Discriminative Classifiers: Naive Bayes and Logistic Regression](http://www.cs.cmu.edu/~tom/mlbook/NBayesLogReg.pdf). This will likely help you to better understand both Naive Bayes and logistic regression, and how they can be thought of as related.
 * The UCLA Institute for Digital Research and Education has a lot of resources on using statistical software, such as: [R Data Analysis Examples: Logit Regression](http://www.ats.ucla.edu/stat/r/dae/logit.htm).
 * For a few general multiclass reduction approaches, read these papers on [Weighted One-Against All](http://hunch.net/~jl/projects/reductions/woa/woa.pdf) and [Error-Correcting Tournaments](http://hunch.net/~beygel/tournament.pdf).
 * Read much more on GLMs with a [chapter](http://www.sagepub.com/upm-data/21121_Chapter_15.pdf) on the topic.
 * Look through a notebook on [logistic regression with statsmodels for well switching in Bangledesh](http://nbviewer.ipython.org/github/carljv/Will_it_Python/blob/master/ARM/ch5/arsenic_wells_switching.ipynb).
